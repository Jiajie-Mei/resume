% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode
% !Mode:: "TeX:UTF-8"

\documentclass{resume}
\usepackage{zh_CN-Adobefonts_external} % Simplified Chinese Support using external fonts (./fonts/zh_CN-Adobe/)
% \usepackage{NotoSansSC_external}
% \usepackage{NotoSerifCJKsc_external}
% \usepackage{zh_CN-Adobefonts_internal} % Simplified Chinese Support using system fonts
\usepackage{linespacing_fix} % disable extra space before next section
\usepackage{cite}

\newlist{InlineList}{enumerate*}{1}
\setlist[InlineList]{label=(\roman*)}


\begin{document}
\pagenumbering{gobble} % suppress displaying page number

\name{梅家洁}

\basicInfo{
  \email{jiajie.mei@buaa.edu.cn} \textperiodcentered\ 
  \phone{(+86) 188 1004 2048} %\textperiodcentered\ 
  %\linkedin[billryan8]{https://www.linkedin.com/in/billryan8}
  }
 
\section{教育背景}
\datedsubsection{\textbf{北京航空航天大学}}{2017.09 -- 2020.01}
\textit{硕士}\ 计算机科学与技术，研究方向：生成模型与知识图谱
\datedsubsection{\textbf{北京航空航天大学}}{2013.09 -- 2017.07}
\textit{学士}\ 计算机科学与技术，保研综合排名29/238

\section{实习经历}
\datedsubsection{\textbf{腾讯微信事业群}，搜索产品中心，导师：刘书凯\&张博}{2019.04 -- 2019.08}
\begin{itemize}
\item 看一看$\cdot$文章推荐（已全量上线）
\begin{itemize}
\item DSSM模型：将用户特征和文章特征分别embedding化，再通过两个MLP分别得到用户和文章的语义表示，通过二者的相似度来召回文章（已例行化）。
\item 测试集离线AUC：0.76。在线实验，两大核心指标：内容曝光点击率+0.41\%，人均停留时长+0.35\%（均显著）。
\item 全量：相比原策略，曝光篇次占比从1.95\%提升到了8.42\%，点击篇次占比从2.70\%提升到了10.44\%。
\end{itemize}
\end{itemize}

\datedsubsection{\textbf{美团点评}， NLP中心，导师：王金刚\&张富峥}{2018.12 -- 2019.03}
\begin{itemize}
\item Query-Aware推荐理由生成（已投稿CIKM2019）
\begin{itemize}
% \item 使用Hive, Hadoop, Spark等工具处理点评的搜索日志，进行数据清洗，导出数据集。
\item 尝试了Pointer-generator模型（用户评论作为原文，推荐理由作为摘要），并在encoder端引入selective gate进一步提升ROUGE性能。
\item 为了让推荐理由与查询相关，将用户查询通过BiLSTM编码，将其引入到encoder和decoder中。该模型取得了最好的自动评测表现 (ROUGE-1/2/L的F1为69.08/63.43/68.29)和人工评测表现（89\%的准确度，3.97/5的可读性，3.17/5的查询相关性）。
\end{itemize}
\end{itemize}

\section{科研经历}
\datedsubsection{\textbf{计算机新技术研究所 (ACT)}， 北航，导师：张日崇\& Yongyi Mao}{2016.08 -- 2018.12}
\begin{itemize}
	\item 知识图谱：{\bf Jiajie Mei}, Richong Zhang, Yongyi Mao, Ting Deng. On Link Prediction in Knowledge Bases: Max-K Criterion and Prediction Protocols (SIGIR2018，CCF信息检索A类会议)
	\begin{itemize}
		\item 观察到top-$k$准则不能在所有的实体预测任务上都取得均衡的查准率 (P) 和查全率 (R)。
		\item 提出使用max-$k$准则，并指出对于理想模型，max-$k$准则的P, R, F1至少和top-$k$的一样好。
		\item 提出了一个符合max-$k$准则的预测协议，即采样协议。
		\item 通过对采样协议进行渐近分析，导出了另一个max-$k$协议——贪心协议。
	\end{itemize}
\item 生成模型（探索性）：
\begin{itemize}
	\item 深入理解Variational AutoEncoder (VAE), 初步研究过VAE在训练时出现KL散度为零问题。我尝试推导线性VAE优化目标的最优解，推导得到KL为零所对应的解确实是一个驻点。
	% \item 了解Generative Adversarial Network (GAN)，曾经想基于它构造一个句子打分器。在初步研究中，构造了一个二维玩具数据集，使用一个判别器与多个生成器对抗，学习数据边界。但是GAN的优化目标内在地决定了最终生成器会打败判别器，这个思路行不通。
\end{itemize}
% \begin{InlineList}
% \item 我，基于它做了一些探索性研究。例如，我初步研究过VAE用于句子生成时常会出现KL散度为零问题。相比现有的一些经验性方法，我尝试推导VAE优化目标的最优解。为此，我构造了一个最简单的线性VAE，推导得到KL为零所对应的解确实是一个驻点。
% \item 我了解GAN，基于它也做过一些探索性研究。我曾经想基于GAN构造一个句子打分器。在初步研究中，我构造了一个二维的玩具数据集，使用多个判别器与一个生成器对抗。但是最终生成器总是能近似生成玩具数据，判别器会失效，达不到打分的目的。后来我意识到，这是GAN的优化目标必定会导致的情况。
% \end{InlineList}


\end{itemize}




\section{技能}
% increase linespacing [parsep=0.5ex]
\begin{itemize}[parsep=0.5ex]
  \item 编程语言: Python > C/C++ > Java
  \item 工具: Tensorflow，Linux，Hadoop，Hive，Pig
  \item 语言: 英语 - 熟练(四级600, 六级581, TOEFL 95)

\end{itemize}

\section{获奖情况}
\datedline{研究生国家奖学金}{2018.09}
\datedline{北京市优秀毕业生}{2017.07}

%% Reference
%\newpage
%\bibliographystyle{IEEETran}
%\bibliography{mycite}
\end{document}
