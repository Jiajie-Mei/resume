% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode
% !Mode:: "TeX:UTF-8"

\documentclass{resume}
\usepackage{zh_CN-Adobefonts_external} % Simplified Chinese Support using external fonts (./fonts/zh_CN-Adobe/)
% \usepackage{NotoSansSC_external}
% \usepackage{NotoSerifCJKsc_external}
% \usepackage{zh_CN-Adobefonts_internal} % Simplified Chinese Support using system fonts
\usepackage{linespacing_fix} % disable extra space before next section
\usepackage{cite}

\newlist{InlineList}{enumerate*}{1}
\setlist[InlineList]{label=(\roman*)}


\begin{document}
\pagenumbering{gobble} % suppress displaying page number

\name{梅家洁}

\basicInfo{
  \email{jiajie.mei@buaa.edu.cn} \textperiodcentered\ 
  \phone{(+86) 188 1004 2048} %\textperiodcentered\ 
  %\linkedin[billryan8]{https://www.linkedin.com/in/billryan8}
  }
 
\section{教育背景}
\datedsubsection{\textbf{北京航空航天大学}}{2013.09 -- 2020.01}
\textit{学士} \& \textit{硕士}\ 计算机科学与技术，本科排名29，硕士研究方向：知识图谱\&生成模型

\section{实习经历}
\datedsubsection{\textbf{腾讯微信事业群}，搜索产品中心，导师：刘书凯\&张博}{2019.04 -- 2019.09}
\begin{itemize}
	\item 看一看精选$\cdot$文章召回（已全量上线）
	\begin{itemize}
		\item \underline{背景}：线上的深度语义匹配（DSSM）策略无法捕捉用户兴趣在一天内发生的变化。
		\item \underline{工作}：将召回策略改成在线召回，即从KV里获取用户的最新特征，基于DSSM计算用户的embedding，近似召回top-$K$篇文章（基于embedding的内积相似度）。
		\item \underline{结果}：在5天的AB实验中，相比原策略，内容曝光点击率+0.41\%（A组：12\%），人均停留时长+0.35\%（A组：14分钟）。全量后，相比原策略，曝光篇次占比从1.95\%提升到了8.42\%，点击篇次占比从2.70\%提升到了10.44\%。
		\item \underline{扩展}：将DSSM应用到小程序视频推荐中，提升分享率和人均播放时长。在4天的AB实验中，相比线上策略，uv分享率+0.69\%（A组：17\%），人均播放时长+1.35\%（A组：14分钟）。
	\end{itemize}
\end{itemize}

\datedsubsection{\textbf{美团点评}， NLP中心，导师：王金刚\&张富峥}{2018.12 -- 2019.03}
\begin{itemize}
	\item Query-Aware推荐理由生成（先后投稿IJCAI和CIKM，未录用）
	\begin{itemize}
		\item \underline{背景}：在大众点评中生成跟用户的query相关的商户推荐理由。
		\item \underline{工作}：将推荐理由视作用户评论的摘要，在Pointer-generator的基础上，将query通过BiLSTM获取表示，将该表示以selective gate的形式引入encoder，以attention的形式引入decoder。
		\item \underline{结果}：相比baseline，该模型取得了最好的自动评测表现 (ROUGE-1/2/L的F1为69.08/63.43/68.29)和人工评测表现（89\%的准确度，3.97/5的可读性，3.17/5的查询相关性）。
	\end{itemize}
\end{itemize}

\section{科研经历}
\datedsubsection{\textbf{计算机新技术研究所 (ACT)}， 北航，导师：张日崇\& Yongyi Mao}{2016.08 -- 2018.12}
\begin{itemize}
	\item 知识图谱：{\bf Jiajie Mei}, Richong Zhang, Yongyi Mao, Ting Deng. On Link Prediction in Knowledge Bases: Max-K Criterion and Prediction Protocols (SIGIR2018，CCF信息检索A类会议)
	\begin{itemize}
		\item \underline{背景}：链接预测模型评估时使用的top-$k$准则不能在所有的预测任务上都取得均衡的准召率。
		\item \underline{工作}：提出max-$k$准则，对于最优模型，max-$k$的准召率是top-$k$的上界。提出最优的max-$k$预测协议，保证最优模型达到最优准召率。将现有链接预测模型容纳到max-$k$准则下做评估。
		\item \underline{结果}：对于现有的非最优模型，其使用max-$k$预测的答案的F1要比使用top-$k$的高，但仍距最优模型有较大差距。
	\end{itemize}
% \item 生成模型（探索性）：
% \begin{itemize}
% 	\item 理解Variational AutoEncoder (VAE), 初步研究过VAE在训练时出现KL散度为零问题。我尝试推导线性VAE优化目标的最优解，推导得到KL为零所对应的解确实是一个驻点。
% 	% \item 了解Generative Adversarial Network (GAN)，曾经想基于它构造一个句子打分器。在初步研究中，构造了一个二维玩具数据集，使用一个判别器与多个生成器对抗，学习数据边界。但是GAN的优化目标内在地决定了最终生成器会打败判别器，这个思路行不通。
% \end{itemize}
% \begin{InlineList}
% \item 我，基于它做了一些探索性研究。例如，我初步研究过VAE用于句子生成时常会出现KL散度为零问题。相比现有的一些经验性方法，我尝试推导VAE优化目标的最优解。为此，我构造了一个最简单的线性VAE，推导得到KL为零所对应的解确实是一个驻点。
% \item 我了解GAN，基于它也做过一些探索性研究。我曾经想基于GAN构造一个句子打分器。在初步研究中，我构造了一个二维的玩具数据集，使用多个判别器与一个生成器对抗。但是最终生成器总是能近似生成玩具数据，判别器会失效，达不到打分的目的。后来我意识到，这是GAN的优化目标必定会导致的情况。
% \end{InlineList}


\end{itemize}




\section{技能}
% increase linespacing [parsep=0.5ex]
\begin{itemize}[parsep=0.5ex]
  \item 编程语言: Python > C/C++ > Java
  \item 工具: Tensorflow，Linux，Hadoop，Hive，Pig
  \item 语言: 英语 - 熟练(四级600, 六级581, TOEFL 95)

\end{itemize}

\section{获奖情况}
\datedline{研究生国家奖学金}{2018.09}
\datedline{北京市优秀毕业生}{2017.07}

%% Reference
%\newpage
%\bibliographystyle{IEEETran}
%\bibliography{mycite}
\end{document}
